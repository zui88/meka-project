\chapter{Deployment / Installation}

In der Objekterkennung hat sich der YOLO Algorithmus bewaehrt. Die YOLO Variante
unterscheidet hauptsaechlich in den Letzten Schichten von anderen \ac{CNN}
Netzwerk Architekturen.

Es gibt mehrere Technologien, die den Aufbau eines Neuronalen Netzwerks
unterstützen. Einige Bibliotheken in Python sind beispielsweise: PyTorch, Keras,
Tensor Flow. Auch Matworks stellt ein eigenes Framework bereit. Vorteil von
Matlab ist: Es gibt sehr viele speziell auf Matlab angepasste Tools für den
kompletten Erstellungs-, Evaluierung- und Anwendungsprozesses. Hingegen die frei
zugänglichen Alternativen wie in Python bieten einen kleineren
Anwendungsbereich. Beispielweise, wenn für die Evaluierung im Bild die Objekte
gekennzeichnet werden sollen, müssen andere Tool als z.\,B. nur Tensor Flow
verwendet werden wie OpenCV zur Bildverarbeitung. OpenCV reichert das Bild mit
Rahmen um erkannte Objekte an und setzt Labels. In Matlab ist alles dabei und
weitere externen Tools sind unnoetig.

Im Projekt wird Matlab als Entwicklungsumgebung verwendet. Vorgängerarbeiten
bauten darauf auf. Würde man sich gegen Matlab als Framework entscheiden, müsste
der Erstellungsprozess von vorne begonnen werden.\\

Losgeloest von den verwendeten Werkzeugen, kann die Installation \emph{engl.
  Deployment} abstrahiert werden, will heissen, der uebergeordnete Vorgang ist
losgeloest von konkreten Technologien --- zu sehen in
\autoref{fig:deployment_jetson}.\\

\begin{figure}[!htb]
  \includegraphics[width=0.9\textwidth]{430/Deployment.png}
  \caption{Die Hauptfunktion wird als Routine geschrieben. Sie verwendet als
    externe Abhaengigkeit das von der Vorgaengergruppe erstellte Neuronales
    Netzwerk. Der Host (f.\,i. Windows PC) uebertraegt Quelldateien auf die
    Zielhardware (JETSON NANO). Dort werden die Quelldateien uebersetzt und eine
    ausfuehrbare Datei \emph{Binary} erstellt (hier: eine statische Library).
    Die Binary verwendet Nvidia CUDA Bibliotheken. Dort werden die aufwendigen
    Berechnungen der Objekerkennung ausgefuehrt. Die Objekterkennung verwendet
    ein Kameramodul.}
  \label{fig:deployment_jetson}
\end{figure}

In diesem Kapitel werden folgende Fragen beantwortet:
\begin{itemize}
  \item Die Installation mittels Matlab. Es wird der konkrete Code --- so wie er
        im Projekt angewendet wird --- beschrieben.
  \item Zusammenfassung / Evaluierung
\end{itemize}




\section{Installation}

Der Vorgang, einen Matlab Algorithmus auf die Zielhardware zu übertragen und
auszuführen, wird in drei Schritten abgearbeitet.\\

\textbf{Schritt 1}: Ein Algorithmus muss erstellt werden. Der Algorithmus hat
die Form einer Routine (Funktion). Die Routine wird in der Matlab IDE erstellt.
Der erstellte Code wird im Laufe des Vorgangs in Cuda Code umgewandelt und in
der Zielhardware uebersetzt (kompiliert). Der Vorgang wird Cross-Kompilierung
genannt.

Jetzt foglt die Beschreibung des Algorithmus. Er ist in der Matlab-Syntax
verfasst. Die Beschreibung setzt sich wie folgt zusammen: erst Code,
anschliessend Erlaeuterung.

\begin{verbatim}
function [x y width height score] = detectFunction()
%codegen
\end{verbatim}
Es wird eine Fnktion deklariert, die fuenf Ausgabewerte liefert. Auch werden
nicht alle Matlab-Interne Funktionen für die Konvertierung unterstützt. In der
Funktion ist die \verb+#codegen+ Direktive zu empfehlen. Es wird dann eine
Prüfung während der Erstellung des Algorithmus durchgeführt, ob Code gültig ist
oder nicht.

\begin{verbatim}
persistant mynet
persistant hwobj
persistant cam

if isempty(mynet) || isempty(hwobj) || isempty(cam)
    hwobj = jetson
    cam   = camera(hwobj, 'vi_output, imx219 6-0010', [1280 720]);
    mynet = coder.loadDeepLearningNetwork('yoloNetwork.mat');
end
\end{verbatim}
Die Variablen \emph{mynet, hwobj, cam} sind mit dem Qualifier \emph{persistant}
versehen. In anlehnung an C hat das den selben Effekt wie eine \emph{static}
Deklaration. Der Code im if-Block wird nur im ersten Funktionsaufruf
ausgefuehrt. Dort werden die Abhaengigkeiten initialisiert.

\begin{verbatim}
img = snapshot(cam);
img = imresize(imt, [224 224]);

[bboxes scores] = detect(mynet, img, 'Threshold', 0.5);
\% only the one with the highest score
[score_ index] = max(scores);
\end{verbatim}
Es wird ein Bild eingefangen --- PiCam --- und dessen Greosse angepasst. Das
verwendete Netzwerk hat 224 mal 224 mal 3 Eingangsneuronen. Der Faktor 3 steht
fuer den RGB Farbaum. Jeder Farbraum wird intern vom Netwerk getrennt berechnet
und am Ende der Pipline wieder zusammengefuehrt. Somit benoetigt ein Farbbild
mehr Rechenleistung. Zukuenftig koennte geprueft werden, ob ein Netzwerk, das
eine Graustufenabbildung verarbeitet erstens genau so zuverslaessig und zweitens
schneller oder genauso schnell rechnet. \emph{detect} ist eine Matlab-Interne
Funktion. Ihr uebergibt man das \ac{KNN}, das interessierende Bild und definiert
einen Schwellwert, ab welchen Zuverlaessigkeitswert ein Objekt auch als das
tatsaechliche Objekt angesehen werden kann oder nicht.

\begin{verbatim}
if ~isempty(bboxes)
   tmp_bbox = bboxes(idx,:);
   x = tmp_bbox(1);
   y = tmp_bbox(2);
   width  = tmp_bbox(3);
   height = tmp_bbox(4);
else
   \% nothing detected
   x = -1
   ...
   score = single(-1);
\end{verbatim}
Wenn Objekt erkannt, wird darum ein Rahmen vom Netzwerk gezogen. Dementsprechen
ist das bbox Objekt nicht leer. Darin sind die Koordinaten der Boudingbox
gespeichert. Im ersten if-Teil werden die Koordinate ausgelesen und den
Ausgangsparametern uebergeben. Wurde kein Objekt erkannt, ist die Boudingbox
leer und es wird nach den Konventionen die Werte ausgefuellt (kein gueltiger
Code --- wie \emph{errno} in C). \\


\textbf{Schritt 2}: Jetzt wird der in Schritt 1 erstellte Algorithmus auf die
Zielhardware uebertragen---JETSON NANO.\@ Dazu muss Verbindung vom Host zur
Zielhardware aufgebaut werden. Matlab verwendet eine SSH Verbindung über
TCP/IP.\@ Die Verbindung wird über ein Hardware Objekt hergestellt.

\begin{itemize}
\item Target: <IP-Address>
\item Login Name: \emph{jestson}
\item Passwort: \emph{1111}
\end{itemize}

Für den Zugriff auf die Hardware des Jetsons muss eine IP-Adresse eingerichtet
werden. Es kann entweder eine statische oder dynamische Adresse vergeben
werden --- seitens der Zielhardware, als JETSON NANO.\@ Mit dem Befehl
\verb+$ ifconfig+ kann die eigene IP-Adresse des Jetsons eingesehen und in der
Matlab IDE eingegeben werden.

\begin{verbatim}
hwobj = jetson(<ip-address>, `jetson', `1111');
\end{verbatim}
Das Hardwareobjekt wird mit den Login Informationen der Zielhardware
--- JETSON NANO --- ausgefuellt. Damit kann eine SSH Verbindung vom Host erstellt
werden.

\begin{verbatim}
gpuEnvObj = coder.gpuEnvConfig('jetson');
gpuEnvConfig.BasicCodegen = 1;
...
results = coder.checkGpuInstall(gpuEnvObj);
\end{verbatim}

\emph{coder} ist eine statische Funktion bereitgestellt von Matlab. Sie erstellt
ein Konfigurationsobjekt, das seinem Randbedingungen unterzogen wird. Jedes
Projekt hat andere Randbedingungen. Demzufolge werden auch in unterschiedlichen
Projekten unterschiedliche Optionen gesetzt. Zuletzt wird das
Konfigurationsobjekt geladen und ueber die zuvor erstellte Verbindung Pruefungen
auf der Zielhardware durchgefuehrt.

Ist die Pruefung erfolgreich durchgefuehrt --- alle Abhaengigkeiten auf
Zielhardware geladen und vorhanden ---, kann der in Schritt eins erstellte
Algorithmus in Code Zielcode umgewandelt werden. Dann erfolgt die Compilierung
auf der Zielhardware. \\


\textbf{Schritt 3}: Der Matlab Coder generiert nun Code --- nur von Funktionen,
nicht von Skripten! Es sollte daher von Anfang an eine Funktion geschrieben
werden, anstatt ein Skript zu erstellen und es hinterher in eine Funktion zu
konvertieren.

Matlab exportiert den Quellcode auf den Jeton. Ist die Übertragung
abgeschlossen, wird auf dem Jetson über den NVIDIA Cuda Compiler \emph{nvcc} der
von Matlab generierte Quellcode in eine ausführbare Datei kompiliert. \\


Zusammengefasst, noetige Schritte für eine Installation sind:

\begin{itemize}
  \item YOLO Netzwerk bereitstellen
  \item Zielhardware konfigurieren
  \item Host konfigurieren
  \item Main-Funktion erstellen
  \item Code generieren
  \item Einbindung der Binary auf Zielhardware
\end{itemize}

\textbf{YOLO Netzwerk}: Es muss ein vorhandenes Netzwerk zur Erkennung von
Objekten vorhanden sein. Getestet wird jeweils das von den Vorgängern erstellte
und neue erstellte Netzwerk.\\

\textbf{Zielhardware}: Auf der Zielhardware müssen zusätzliche Bibliotheken
installiert und Globale Systemvariablen exportiert werden. Benötigte Bibliothek
ist die \emph{Simple Direct Medial Layer v1.2} in der standart und developement
Version. Der Cuda Pfad, in dem die Cuda Binaries und die Cuda Bibliotheken liegen,
kann beispielsweise in der \emph{.bashrc} hinterlegt werden.\\

\textbf{Host}: Die Codegenerierung --- C++ und Cuda --- sind von externen Tools
abhaengig. Matlab benutzt die \emph{Gnu Compiler Collection} und mehrere
\emph{Cuda Libraries} von Nvidia für die Erstellung der Binaries. In Linux ist
der gcc standardmäßig in den Repos hinterlegt. Auf Windows Maschinen heißt das
Compiler Paket MinGW. Die Abhängigkeiten seitens Nvidia müssen von deren
Homepage heruntergeladen und installiert werden. Es werden Windos- und
Linuxsysteme unterstützt.\\

\textbf{Main-Funktion}: Funktion, die in einer Endlosschleife Bilder von
der Webcam aufnimmt und dem Detektor uebergibt. Der Detektor scannt
das aufgenommene Bild nach Objekten. Wenn Objekte gefunden wurde, dann
wird die entsprechende Bounding Box und Label auf das Bild gebunden
und anschließend auf dem Bildschirm angezeigt. Hierbei muss entweder
ein externer Monitor an den Jetson angeschlossen werden oder eine
Remote- hergestellt werden.\\

\textbf{Code Generation}: Der Code wird in der Matlab Umgebung mit ein paar
Codezeilen generiert. Das Kompilat kann auf mehreren Wegen auf den Jetson
überspielt werden. Entweder über einem USB, via Ethernet Verbindung, etc.
\dots. Man kann allgemein die Binaries in einem beliebigen Pfad installieren. Es
muss nur darauf geachtete werden, dass die ausführbaren Dateien hinterher in
den Pfad angefügt werden.\\

\textbf{Zielhardware}: Es ist nicht zwingend, eine ausführbare Datei zu
erstellen. Eine weitere Möglichkeit ist, statische oder dynamische Bibliotheken
zu generieren. Die Bibliotheken können dann in einem anderen Programm
eingebunden werden. Der Vorteil, den Code fuer den Jetson direkt in Matlab als
Executable zu generieren, ist, es müssen keine zusätzlichen Einstellungen
getroffen werden.\\




\section{Zusammenfassung}

Es wurde ein Algorithmus fuer die Objekterkennung vorgestellt. Der Algorithmus
verwendet das Kameramodul, um in Echtzeit die Umgebung aufzunehmen und
auszuwerten. Der Algorithmus ist so geschrieben, dass er in der uebergeordneten
Umgebung zyklisch aufgerufen und abgefragt werden kann \emph{Polling}.

Es wurde weiterhin die Installation des Algorithmus ausgehend von Matlab auf das
Zieldevice \emph{JETSON NANO} gezeigt. Die Installationsroutine kann als Matlab
Skript umgesetzt werden und ist auch so umgesetzt worden.

Der komplette Installationprozess ist graphisch in
\autoref{fig:workflow_deployment_jetson} nochmals aufgezeigt.

\begin{figure}[!htb]
  \includegraphics[width=0.9\textwidth]{430/Workflow_Deployment.png}
  \caption{Die Zielhardware (Jetson) und der Host (f.i. WIN oder UNIX) muss
    eingerichtet werden. Die Reihenfolge der Einrichtung spielt keine Rolle. Der
    Quellcode wird im Host generiert und wird auf die Zielhardware uebertragen.
    Im Jetson wird eine static Library generiert. Die Library wird in ein
    eigenes Cuda Projekt eingebunden und hieraus ein ausfuehrbares Programm
    generiert.}
  \label{fig:workflow_deployment_jetson}
\end{figure}
